{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e45d05a7e6705e7bc18fff5d5890ef58",
     "grade": false,
     "grade_id": "cell-44ca835c70f3040a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-08T13:27:28.104998Z",
     "start_time": "2024-02-08T13:27:28.077628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "IPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false; // disable scroll bar when displaying Folium map\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false; // disable scroll bar when displaying Folium map\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae6111747a75bdb5c5393f44d1045577",
     "grade": false,
     "grade_id": "cell-c676d66924c74eea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "Before working on this assignment please read these instructions fully. In the submission area, you will notice that you can click the link to **Preview the Grading** for each step of the assignment. This is the criteria that will be used for peer grading. Please familiarize yourself with the criteria before beginning the assignment.\n",
    "\n",
    "The data for this assignment comes from a subset of The National Centers for Environmental Information (NCEI) [Global Historical Climatology Network daily (GHCNd)](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily) (GHCN-Daily). The GHCN-Daily is comprised of daily climate records from thousands of land surface stations across the globe - it's a wonderfully large dataset to play with! In particular, you will be asked to use data from the Ann Arbor Michigan location (my home!). and this is stored in the file: `assets/fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89.csv`\n",
    "\n",
    "Each row in this datafile corresponds to a single observation from a weather station, and has the following variables:\n",
    "* **id** : station identification code\n",
    "* **date** : date in YYYY-MM-DD format (e.g. 2012-01-24 = January 24, 2012)\n",
    "* **element** : indicator of element type\n",
    "    * TMAX : Maximum temperature (tenths of degrees C)\n",
    "    * TMIN : Minimum temperature (tenths of degrees C)\n",
    "* **value** : data value for element (tenths of degrees C)\n",
    "\n",
    "For this assignment, you must:\n",
    "\n",
    "1. Read the documentation and familiarize yourself with the dataset, then write a python notebook which plots line graphs of the record high and record low temperatures by day of the year over the period 2005-2014. The area between the record high and record low temperatures for each day should be shaded.\n",
    "2. Overlay a scatter of the 2015 data for any points (highs and lows) for which the ten year record (2005-2014) record high or record low was broken in 2015. (Based on the graph, do you think extreme weather is getting more frequent in 2015?)\n",
    "3. Watch out for leap days (i.e. February 29th), it is reasonable to remove these points from the dataset for the purpose of this visualization.\n",
    "4. Make the visual nice! Leverage principles from the first module in this course when developing your solution. Consider issues such as legends, labels, and chart junk.\n",
    "\n",
    "I've written some steps I think would be good to go through, but there are other ways to solve this assignment so feel free to explore the pandas library! What I really want to see is an image that looks like this sketch I drew at my desk:\n",
    "\n",
    "![](assets/chris_sketch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8d9355fc55599cd2ad34fdd140baac1",
     "grade": false,
     "grade_id": "cell-f01cb0e8645e7c07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-04T11:25:45.654707Z",
     "start_time": "2024-02-04T11:25:43.770299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<folium.folium.Map at 0x118eb3790>",
      "text/html": "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n    \n    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n    \n        &lt;script&gt;\n            L_NO_TOUCH = false;\n            L_DISABLE_3D = false;\n        &lt;/script&gt;\n    \n    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n    \n            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n            &lt;style&gt;\n                #map_aa8483d3208bfe924f488e4bf5d65986 {\n                    position: relative;\n                    width: 100.0%;\n                    height: 500.0px;\n                    left: 0.0%;\n                    top: 0.0%;\n                }\n                .leaflet-container { font-size: 1rem; }\n            &lt;/style&gt;\n        \n&lt;/head&gt;\n&lt;body&gt;\n    \n    \n            &lt;div class=&quot;folium-map&quot; id=&quot;map_aa8483d3208bfe924f488e4bf5d65986&quot; &gt;&lt;/div&gt;\n        \n&lt;/body&gt;\n&lt;script&gt;\n    \n    \n            var map_aa8483d3208bfe924f488e4bf5d65986 = L.map(\n                &quot;map_aa8483d3208bfe924f488e4bf5d65986&quot;,\n                {\n                    center: [41.9164, -84.0158],\n                    crs: L.CRS.EPSG3857,\n                    zoom: 9,\n                    zoomControl: true,\n                    preferCanvas: false,\n                }\n            );\n\n            \n\n        \n    \n            var tile_layer_0d18171b94484310954ac4c8f782b058 = L.tileLayer(\n                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n            );\n        \n    \n            tile_layer_0d18171b94484310954ac4c8f782b058.addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_58bc7ed978af526712715147a3f38881 = L.marker(\n                [41.9164, -84.0158],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_74e15cfdaa66ddb89e13208f41d6f292 = L.marker(\n                [42.2875, -83.7611],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_e3dda4e1fe28935df125bd88e661cf4b = L.marker(\n                [42.2417, -83.6933],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_0af40d432610961d2730ec8df7e5856e = L.marker(\n                [42.2947, -83.7108],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_d09e4850bb8d066c07d36a50bea88593 = L.marker(\n                [41.84, -83.8608],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_8242bfa79d660d447e3cf3f336fcbdb6 = L.marker(\n                [42.0636, -83.4358],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_accf8107a75714b4bc44219b66caaed9 = L.marker(\n                [42.3264, -84.0133],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_fa31adf0633d37eaa2bba46f2e80291c = L.marker(\n                [41.9553, -83.6489],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_25fe566bcaf75940b0392f1b7b8f2e34 = L.marker(\n                [42.4344, -83.9858],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_506a9c42887ef394b1efcf1a5728ee64 = L.marker(\n                [42.1508, -84.0236],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_4e53c0169c78f52c2a42fea0ee2790a9 = L.marker(\n                [42.0664, -83.6186],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_2e8548a0b154872aac0b4f291797e271 = L.marker(\n                [42.0811, -83.6769],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_faaeb776c77c6398e899a2ca8362d5c6 = L.marker(\n                [41.9069, -83.4158],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_61a2b14644421abf4cf305bd6d044841 = L.marker(\n                [41.9497, -83.28],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_481bb450b5505bea9f32b13580c8ad74 = L.marker(\n                [42.1611, -83.7819],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_267108711369ec7e67d7cb146386588f = L.marker(\n                [42.1236, -83.82],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_9e32df101d231050924f1803eb144a5d = L.marker(\n                [41.8069, -83.5831],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_eb570151b47fb379ad7b06606d8303ee = L.marker(\n                [42.0028, -83.9336],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_555c3a5d9b95db26c3ad1ae389660aef = L.marker(\n                [42.0283, -84.1108],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_4b895409d6a07cef87d8a5e2e86c309f = L.marker(\n                [42.4356, -83.7831],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_b71ad25cd0d3314b3cb4ca71b3d6af50 = L.marker(\n                [41.5631, -83.4764],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_73197ab476621025a6c8105d30dc85cf = L.marker(\n                [42.2667, -84.4667],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_f1184e67b0315ac9ae8bec3fd1823b0d = L.marker(\n                [42.2333, -83.5333],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n    \n            var marker_d003856fd1567e291fba31dd858ca23b = L.marker(\n                [42.2228, -83.7444],\n                {}\n            ).addTo(map_aa8483d3208bfe924f488e4bf5d65986);\n        \n&lt;/script&gt;\n&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  I'll be using the folium package to render the data into a map in Jupyter.\n",
    "\n",
    "import folium\n",
    "import pandas as pd\n",
    "\n",
    "# get the location information for this dataset\n",
    "df = pd.read_csv('assets/BinSize_d400.csv')\n",
    "station_locations_by_hash = df[df['hash'] == 'fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89']\n",
    "\n",
    "# get longitude and lattitude to plot\n",
    "lons = station_locations_by_hash['LONGITUDE'].tolist()\n",
    "lats = station_locations_by_hash['LATITUDE'].tolist()\n",
    "\n",
    "# plot on a beautiful folium map\n",
    "my_map = folium.Map(location = [lats[0], lons[0]], height = 500,  zoom_start = 9)\n",
    "for lat, lon in zip(lats, lons):\n",
    "    folium.Marker([lat, lon]).add_to(my_map)\n",
    "\n",
    "# render map in Jupyter\n",
    "display(my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2ee9d3c5ac53844b3ed48aa157f6204",
     "grade": false,
     "grade_id": "cell-695e4689bc5509b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 1\n",
    "Load the dataset and transform the data into Celsius (refer to documentation) then extract all of the rows which have minimum or maximum temperatures.\n",
    "\n",
    "__hint: when I did this step I had two DataFrame objects, each with ~80,000 entries in it__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbfe393a2232a653ebbd81e518237a83",
     "grade": false,
     "grade_id": "cell-f508059dd84e9b7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "ExecuteTime": {
     "end_time": "2024-02-08T13:45:10.474974Z",
     "start_time": "2024-02-08T13:45:00.531878Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            ID        Date Element  Data_Value\n0  USW00094889  2014-11-12    TMAX          22\n1  USC00208972  2009-04-29    TMIN          56\n2  USC00200032  2008-05-26    TMAX         278\n3  USC00205563  2005-11-11    TMAX         139\n4  USC00200230  2014-02-27    TMAX        -106",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Date</th>\n      <th>Element</th>\n      <th>Data_Value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>USW00094889</td>\n      <td>2014-11-12</td>\n      <td>TMAX</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>USC00208972</td>\n      <td>2009-04-29</td>\n      <td>TMIN</td>\n      <td>56</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>USC00200032</td>\n      <td>2008-05-26</td>\n      <td>TMAX</td>\n      <td>278</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>USC00205563</td>\n      <td>2005-11-11</td>\n      <td>TMAX</td>\n      <td>139</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>USC00200230</td>\n      <td>2014-02-27</td>\n      <td>TMAX</td>\n      <td>-106</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('assets/fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T15:19:18.284705Z",
     "start_time": "2024-02-08T15:19:18.213735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((83063, 5), (82022, 5))"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this code cell, transform the Data_Value column\n",
    "df[\"Celsius\"] = (df[\"Data_Value\"] - 32)*5/9\n",
    "max_temps = df[df[\"Element\"] == \"TMAX\"]\n",
    "min_temps = df[df[\"Element\"] == \"TMIN\"]\n",
    "max_temps.shape, min_temps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76f2478088402765c38ed2b9db771916",
     "grade": false,
     "grade_id": "cell-c5718635688cb408",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2\n",
    "In order to visualize the data we would plot the min and max data for each day of the year between the years 2005 and 2014 across all weather stations. But we also need to find out when the min or max temperature in 2015 falls below the min or rises above the max for the previous decade.\n",
    "\n",
    "If you did step 1 you have two Series objects with min and max times for the years 2005 through 2015. You can use Pandas `groupby` to create max and min temperature Series objects across all weather stations for each day of these years, and you can deal with the records for February 29 (the leap year) by dropping them.\n",
    "\n",
    "__hint: when I finished this step, I had two DataFrame objects, each with exactly 4015 observations in them__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T15:19:23.530137Z",
     "start_time": "2024-02-08T15:19:22.446198Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hc/dvc94mw13w5gvc0rlv0rbzbw0000gn/T/ipykernel_92846/1213919489.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  max_temps[\"Date\"] = pd.to_datetime(max_temps[\"Date\"])\n",
      "/var/folders/hc/dvc94mw13w5gvc0rlv0rbzbw0000gn/T/ipykernel_92846/1213919489.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  min_temps[\"Date\"] = pd.to_datetime(min_temps[\"Date\"])\n",
      "/var/folders/hc/dvc94mw13w5gvc0rlv0rbzbw0000gn/T/ipykernel_92846/1213919489.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  max_temps[\"Month\"] = max_temps[\"Date\"].dt.month\n",
      "/var/folders/hc/dvc94mw13w5gvc0rlv0rbzbw0000gn/T/ipykernel_92846/1213919489.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  max_temps[\"Day\"] = max_temps[\"Date\"].dt.day\n",
      "/var/folders/hc/dvc94mw13w5gvc0rlv0rbzbw0000gn/T/ipykernel_92846/1213919489.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  min_temps[\"Month\"] = min_temps[\"Date\"].dt.month\n",
      "/var/folders/hc/dvc94mw13w5gvc0rlv0rbzbw0000gn/T/ipykernel_92846/1213919489.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  min_temps[\"Day\"] = min_temps[\"Date\"].dt.day\n"
     ]
    },
    {
     "data": {
      "text/plain": "((4015, 6), (4015, 6))"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a DataFrame of maximum temperature by date\n",
    "\n",
    "max_temps[\"Date\"] = pd.to_datetime(max_temps[\"Date\"])\n",
    "min_temps[\"Date\"] = pd.to_datetime(min_temps[\"Date\"])\n",
    "max_temps[\"Month\"] = max_temps[\"Date\"].dt.month\n",
    "max_temps[\"Day\"] = max_temps[\"Date\"].dt.day\n",
    "min_temps[\"Month\"] = min_temps[\"Date\"].dt.month\n",
    "min_temps[\"Day\"] = min_temps[\"Date\"].dt.day\n",
    "max_temps = max_temps[~((max_temps[\"Month\"] == 2) & (max_temps[\"Day\"] == 29))]\n",
    "min_temps = min_temps[~((min_temps[\"Month\"] == 2) & (min_temps[\"Day\"] == 29))]\n",
    "\n",
    "max_temps_by_date = max_temps.groupby(\"Date\").max()\n",
    "# create a DataFrame of minimum temperatures by date\n",
    "min_temps_by_date = min_temps.groupby(\"Date\").min()\n",
    "\n",
    "max_temps_by_date.shape, min_temps_by_date.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0edac9c92f1b79eb9b21f302a3259c5e",
     "grade": false,
     "grade_id": "cell-d3a1a2647a47fe31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 3\n",
    "Now that you have grouped the daily max and min temperatures for each day of the years 2005 through 2015, you can separate out the data for 2015. Then you can use the Pandas `groupby` function to find the max and min of the temperature data for each __day of the year__ for the 2005-2014 data.\n",
    "\n",
    "__hint: at the end of this step I had two DataFrames, one of maximum and the other of minimum values, which each had 365 observations in them. I also had another pair of similar DataFrames but only for the year 2015.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T15:26:25.799025Z",
     "start_time": "2024-02-08T15:26:25.395482Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "((365, 6), (365, 6))"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the minimum and maximum values for the day of the year for 2005 through 2014\n",
    "max_temps_2005_2014 = max_temps[(max_temps[\"Date\"] >= \"2005-01-01\") & (max_temps[\"Date\"] < \"2014-12-31\")]\n",
    "min_temps_2005_2014 = min_temps[(min_temps[\"Date\"] >= \"2005-01\") & (min_temps[\"Date\"] <= \"2014-12-31\")]\n",
    "max_temps_2005_2014 = max_temps_2005_2014.groupby([\"Month\", \"Day\"]).max()\n",
    "min_temps_2005_2014 = min_temps_2005_2014.groupby([\"Month\", \"Day\"]).min()\n",
    "\n",
    "# calculate the minimum and maximum values for the years 2015\n",
    "max_temps[\"Year\"] = max_temps[\"Date\"].dt.year\n",
    "min_temps[\"Year\"] = min_temps[\"Date\"].dt.year\n",
    "max_temp_2015 = max_temps[max_temps[\"Year\"] == 2015]\n",
    "max_temps_2015 = max_temp_2015.groupby([\"Month\", \"Day\"]).max()\n",
    "min_temps_2015 = min_temps[min_temps[\"Year\"] == 2015]\n",
    "min_temps_2015 = min_temps_2015.groupby([\"Month\", \"Day\"]).min()\n",
    "max_temps_2015.shape, min_temps_2015.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7de066a05b833f7ded9353ee2215ba8",
     "grade": false,
     "grade_id": "cell-25711f5fdbe49515",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 4\n",
    "Now it's time to plot! You need to explore matplotlib in order to plot line graphs of the min and max temperatures for the years 2005 through 2014 and to scatter plot __only__ the daily 2015 temperatures that exceeded those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from calendar import month_abbr\n",
    "\n",
    "# put your plotting code here!"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mooc_adswpy_v1_assignment2"
   ]
  },
  "kernelspec": {
   "name": "python3.11",
   "language": "python",
   "display_name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
